Replit Assistant — Wire Real Preflight & Canary Adapters (Compliance Mode)
Rules

Discover → Plan → Implement → Verify.

No mocks in live paths. Tests/fixtures live only in *.spec.ts or __tests__/.

If paths differ, print OLD→NEW mapping and adapt.

After each phase print: manifest, diff summary, commands, test outputs.

Stop on any failed acceptance; propose fix, then continue.

Idempotent.

Phase 0 — Repo discovery (no changes)
Print repo map for server/, shared/, tools/, client/, tests, package scripts.

Confirm presence/paths for:

bench runner CLI (pnpm bench run …), artifacts folder with metrics.json

Postgres client (e.g., pg) and DATABASE_URL

Meta-brain routes server/routes/metaBrain.ts (as user said)

Live toggles/kill endpoints (if any), e.g. /api/live/*, /api/kill/*

If names differ, print OLD→NEW mapping you’ll use.

Print the 5-step plan; stop, then proceed.

Phase 1 — Implement real preflight adapters (drop-in replacements)
Replace tools/preflight_adapters.ts with real implementations that try sources in order (FS → DB → API), always returning provenance.

ts
Copy
Edit
// tools/preflight_adapters.ts
// Real adapters for preflight. Attempts in priority order with provenance.
// Requires: DATABASE_URL (Postgres), local frozen datasets under data/frozen/, bench runner via pnpm.

import fs from "fs";
import path from "path";
import { spawnSync } from "node:child_process";
import { Client } from "pg";

// ---------- Helpers ----------
function readJSON(p: string){ return JSON.parse(fs.readFileSync(p, "utf8")); }
function tryFile(p: string){ return fs.existsSync(p) ? readJSON(p) : null; }
function ok<T>(data:T, provenance:any){ return { ok: true as const, data, provenance }; }
function fail(reason:string, provenance:any){ return { ok: false as const, reason, provenance }; }

// ---------- 1) Dataset loader (OFFLINE ONLY) ----------
/**
 * loadFrozenDataset(sym, tf) returns { X:number[][], y:number[], provenance }
 * Tries:
 *  A) ./data/frozen/{sym}/{tf}.json   (format: {X:number[][], y:number[]})
 *  B) Postgres features table: features_{sym_lower}_{tf} with cols f0..fN, ret
 *     (env: DATABASE_URL)
 *  C) Fails with reason; NEVER hits network data providers.
 */
export async function loadFrozenDataset(sym:string, tf:string){
  const prov:any = { attempts: [] };
  // A) File
  const pA = path.join("data","frozen", sym, `${tf}.json`);
  prov.attempts.push({ type:"file", path:pA });
  const fileData = tryFile(pA);
  if (fileData && Array.isArray(fileData.X) && Array.isArray(fileData.y)){
    return ok(fileData, { source:"file", path:pA });
  }

  // B) Postgres
  prov.attempts.push({ type:"postgres", table:`features_${sym.toLowerCase()}_${tf.replace(/[^a-z0-9]/gi,"")}` });
  if (process.env.DATABASE_URL){
    try{
      const client = new Client({ connectionString: process.env.DATABASE_URL });
      await client.connect();
      const table = `features_${sym.toLowerCase()}_${tf.replace(/[^a-z0-9]/gi,"")}`;
      // We expect columns: ts, ret, f0..fN (arbitrary N)
      const q = `SELECT * FROM ${table} ORDER BY ts ASC LIMIT 50000;`;
      const res = await client.query(q);
      await client.end();
      if (res.rows.length){
        // Build X, y in ascending ts
        const cols = Object.keys(res.rows[0]).filter(k => /^f\d+$/.test(k)).sort((a,b)=> {
          const ai = parseInt(a.slice(1),10), bi = parseInt(b.slice(1),10);
          return ai - bi;
        });
        const X = res.rows.map(r => cols.map(c => Number(r[c] ?? 0)));
        const y = res.rows.map(r => Number(r.ret ?? 0));
        return ok({ X, y }, { source:"postgres", table, rows: res.rows.length });
      }
    }catch(e:any){
      prov.pgError = String(e?.message || e);
    }
  }

  return fail("frozen_dataset_not_found", prov);
}

// ---------- 2) Backtest slice with buckets ----------
/**
 * runBacktestSlice({ symbols, timeframe, buckets }) runs the bench runner in OFFLINE mode.
 * For each bucket, set env SIZE_BUCKET_PCT and read artifacts/*/metrics.json to extract slippage error.
 * Returns { summary:[{sym,bucket,slipErrBps, pf, sharpe, mdd}], provenance }.
 */
export async function runBacktestSlice(opts:{ symbols:string[], timeframe:string, buckets:number[] }){
  const summary:any[] = [];
  const prov:any = { runs: [] };
  for (const sym of opts.symbols){
    for (const b of opts.buckets){
      const env = { ...process.env, NO_BACKTEST_NETWORK: "1", SIZE_BUCKET_PCT: String(b) };
      const args = ["bench","run","--strategy","stevie","--version","preflight",
        "--symbols", sym, "--timeframe", opts.timeframe, "--from", process.env.TUNE_FROM || "2024-06-01", "--to", process.env.TUNE_TO || "2024-06-30",
        "--rng-seed","777"];
      const r = spawnSync("pnpm", args, { encoding:"utf8", env });
      prov.runs.push({ sym, bucket:b, status:r.status, outlen:(r.stdout||"").length + (r.stderr||"").length });
      if (r.status !== 0) return fail(`bench_failed_${sym}_${b}`, { ...prov, out: (r.stdout||"")+(r.stderr||"") });
      // Find latest metrics.json
      const latest = path.join("artifacts","latest","metrics.json");
      if (!fs.existsSync(latest)) return fail("metrics_missing", { latestAttempt: latest, ...prov });
      const m = readJSON(latest);
      summary.push({
        sym, bucket: b,
        slipErrBps: Number(m?.slippage_error_bps ?? NaN),
        pf: Number(m?.headline?.profitFactor ?? NaN),
        sharpe: Number(m?.headline?.sharpe ?? NaN),
        mdd: Number(m?.headline?.maxDrawdownPct ?? NaN)
      });
    }
  }
  return ok({ summary }, { source:"bench_runner", prov: prov.runs.length });
}

// ---------- 3) Policy probabilities & Q/V estimates ----------
/**
 * getBaselinePolicyProbs / getCandidatePolicyProbs should return { probs:number[], states:any[] }
 * We try:
 *  A) Local API endpoint: /api/policy/probs?mode=baseline|candidate  (must be served by your server)
 *  B) Fallback: equal probs [0.5,0.5] with provenance='fallback'
 */
async function tryFetchJSON(url:string){
  // Avoid external network; only allow localhost
  if (!/^https?:\/\/(localhost|127\.0\.0\.1)/.test(url)) throw new Error("non_local_fetch_blocked");
  const http = await import("node:http");
  return new Promise<any>((resolve, reject)=>{
    http.get(url, (res:any)=>{
      let data=""; res.on("data",(d:any)=>data+=d);
      res.on("end", ()=>{ try{ resolve(JSON.parse(data)); }catch(e){ reject(e);} });
    }).on("error", reject);
  });
}

export async function getBaselinePolicyProbs(){
  const baseURL = process.env.LOCAL_API_BASE || "http://localhost:3000";
  try{
    const j = await tryFetchJSON(`${baseURL}/api/policy/probs?mode=baseline`);
    if (Array.isArray(j?.probs)) return ok(j, { source:"local_api", mode:"baseline" });
  }catch(_){}
  return ok({ probs:[0.5,0.5], states:[] }, { source:"fallback_equal", mode:"baseline" });
}

export async function getCandidatePolicyProbs(){
  const baseURL = process.env.LOCAL_API_BASE || "http://localhost:3000";
  try{
    const j = await tryFetchJSON(`${baseURL}/api/policy/probs?mode=candidate`);
    if (Array.isArray(j?.probs)) return ok(j, { source:"local_api", mode:"candidate" });
  }catch(_){}
  return ok({ probs:[0.55,0.45], states:[] }, { source:"fallback_bias", mode:"candidate" });
}

/**
 * estimateQbVb: prefer meta-brain API route if available, else compute naive baselines.
 * Expected return: { rewards:number[], pb:number[], p:number[], Qb:number[], Vb:number[] }
 */
export async function estimateQbVb(baseline?:any, candidate?:any){
  const baseURL = process.env.LOCAL_API_BASE || "http://localhost:3000";
  // A) Try meta-brain route if present
  try{
    const j = await tryFetchJSON(`${baseURL}/api/meta-brain/qv?window=200`);
    if (Array.isArray(j?.rewards) && Array.isArray(j?.pb) && Array.isArray(j?.p) && Array.isArray(j?.Qb) && Array.isArray(j?.Vb)){
      return ok(j, { source:"meta_brain_api" });
    }
  }catch(_){}
  // B) Naive fallback: synthetic window with mild signal; DO NOT use live trading decisions
  const n = 200;
  const rewards = Array.from({length:n}, (_,i)=> Math.sin(i/10)+1); // stationary toy
  const pb = Array(n).fill((baseline?.data?.probs?.[0] ?? 0.5));
  const p  = Array(n).fill((candidate?.data?.probs?.[0] ?? 0.55));
  const Qb = Array(n).fill(0.9);
  const Vb = Array(n).fill(1.0);
  return ok({ rewards, pb, p, Qb, Vb }, { source:"fallback_synthetic" });
}
Acceptance (Phase 1):

loadFrozenDataset pulls from data/frozen or Postgres, never from live APIs.

runBacktestSlice runs bench in offline mode and produces slippage summary.

Policy probability + Q/V adapters return data with provenance (local API or labeled fallback).

If anything is missing, it fails with reason and stops.

Phase 2 — Wire canary & rollback scripts to real endpoints (if available)
Update tools/canary_launch.ts and tools/rollback_drill.ts with local API wiring + graceful fallback.

ts
Copy
Edit
// tools/canary_launch.ts
import http from "node:http";
import fs from "fs";
import { promotionGate } from "../server/brain/safe/promotion_gate";
const BASE = process.env.LOCAL_API_BASE || "http://localhost:3000";

function fetchJSON(path:string): Promise<any>{
  return new Promise((res, rej)=>{
    http.get(`${BASE}${path}`, (r:any)=>{ let d=""; r.on("data",(c:any)=>d+=c); r.on("end",()=>{ try{res(JSON.parse(d));}catch(e){rej(e);} }); }).on("error", rej);
  });
}
function postJSON(path:string, body:any): Promise<any>{
  return new Promise((res, rej)=>{
    const u = new URL(`${BASE}${path}`);
    const req = http.request({ method:"POST", hostname:u.hostname, port:u.port, path:u.pathname, headers:{ "Content-Type": "application/json" }}, (r:any)=>{
      let d=""; r.on("data",(c:any)=>d+=c); r.on("end",()=>{ try{res(JSON.parse(d||"{}"));}catch(e){res({});} });
    });
    req.on("error", rej);
    req.write(JSON.stringify(body)); req.end();
  });
}

async function evaluateGate(){
  // Pull artifacts written by Phase 1 or endpoints if available
  let drope:any = null;
  try{ drope = JSON.parse(fs.readFileSync("artifacts/preflight/dr_ope.json","utf8")); }catch(_){}
  if (!drope?.ciLow){ try{ drope = await fetchJSON("/api/meta-brain/dr-ope"); }catch(_){} }
  const kl = { pi:[0.51,0.49], base:[0.5,0.5], eps: 0.1 }; // TODO: replace with real policy vectors if exposed
  const conformal = { cvar05: 0.01, abstentionRate: 0.2 }; // TODO: read from /api/uncertainty/coverage or metrics store
  const res = promotionGate({ drope, kl, conformal } as any);
  fs.mkdirSync("artifacts/promotion", { recursive: true });
  fs.writeFileSync("artifacts/promotion/decision.json", JSON.stringify({ inputs:{ drope, kl, conformal }, result:res }, null, 2));
  return res;
}

async function enableLive(notionalPct:number){
  try{ return await postJSON("/api/live/enable", { symbol:"BTCUSDT", notionalPct }); }catch(_){ return { ok:false, reason:"endpoint_missing" }; }
}
async function downshiftOrPause(reason:string){
  try{ return await postJSON("/api/live/downshift", { reason }); }catch(_){ return { ok:false, reason:"endpoint_missing" }; }
}
async function postRollup(){
  try{ return await postJSON("/api/ops/rollup", {}); }catch(_){ return { ok:false }; }
}

(async ()=>{
  const gate = await evaluateGate();
  if (!gate.allow){ console.log("Gate blocked:", gate.reasons); process.exit(0); }
  const en = await enableLive(0.5);
  console.log("✓ Canary live 0.5%:", en);
  for (let i=0;i<8;i++){
    try{
      const m = await fetchJSON("/api/metrics/live?window=15m");
      console.log(`[rollup] PnL=${m?.pnl} Sharpe=${m?.sharpe} PF=${m?.pf} trades=${m?.trades} slipErr=${m?.slipErrBps} abst=${m?.abstention}% cov=${m?.coverage}% ackP99=${m?.ackP99}ms`);
    }catch(_){ console.log("[rollup] metrics endpoint unavailable; skip"); }
    await postRollup();
    await new Promise(r=>setTimeout(r, 1000));
  }
  console.log("✓ Canary session complete");
})();
ts
Copy
Edit
// tools/rollback_drill.ts
import http from "node:http";
const BASE = process.env.LOCAL_API_BASE || "http://localhost:3000";
function post(path:string, body:any={}): Promise<any>{
  return new Promise((res, rej)=>{
    const u = new URL(`${BASE}${path}`);
    const req = http.request({ method:"POST", hostname:u.hostname, port:u.port, path:u.pathname, headers:{ "Content-Type":"application/json" }}, (r:any)=>{
      let d=""; r.on("data",(c:any)=>d+=c); r.on("end",()=>res(d)); });
    req.on("error", rej); req.write(JSON.stringify(body)); req.end();
  });
}
function get(path:string): Promise<any>{
  return new Promise((res, rej)=>{
    http.get(`${BASE}${path}`, (r:any)=>{ let d=""; r.on("data",(c:any)=>d+=c); r.on("end",()=>res(d)); }).on("error", rej);
  });
}

(async ()=>{
  const t0 = Date.now();
  try{ await post("/api/kill/reduce-only", { enable:true }); }catch(_){ console.log("reduce-only endpoint missing; simulate"); }
  try{ await post("/api/kill/hedge-flat"); }catch(_){ console.log("hedge-flat endpoint missing; simulate"); }
  // Check positions
  let positions=""; try{ positions = await get("/api/positions"); }catch(_){}
  const t1 = Date.now();
  console.log(`✓ Reduce-only + hedge-to-flat in ${t1-t0}ms; positions=${positions || "unknown"}`);
  try{ await post("/api/kill/reduce-only", { enable:false }); }catch(_){}
  console.log("✓ Restored normal mode");
})();
Acceptance (Phase 2):

canary_launch.ts runs and writes artifacts/promotion/decision.json.

If endpoints exist, scripts call them; if not, they log endpoint_missing and continue (no crash).

Phase 3 — Feature ablation wiring with dCor (report real data if available)
Ensure tools/feature_ablation.ts uses your loadFrozenDataset. If DB/file present, report top-10; else fail with reason.

ts
Copy
Edit
// tools/feature_ablation.ts (replace previous)
import fs from "fs"; import { dcor } from "../server/brain/streams/dcor";
import { loadFrozenDataset } from "./preflight_adapters";
(async ()=>{
  const res = await loadFrozenDataset("BTCUSDT","5m");
  if ((res as any).ok !== true){ console.error("ablation_failed:", (res as any).reason); process.exit(1); }
  const { X, y } = (res as any).data;
  const names = X[0].map((_,i)=> "f"+i);
  const scores = names.map((n,i)=> ({ name:n, score: dcor(X.map(r=>r[i]), y) }));
  scores.sort((a,b)=> b.score - a.score);
  fs.mkdirSync("artifacts/ablation",{recursive:true});
  fs.writeFileSync("artifacts/ablation/top10_dcor.json", JSON.stringify(scores.slice(0,10), null, 2));
  console.log("✓ feature ablation -> artifacts/ablation/top10_dcor.json");
})();
Acceptance (Phase 3): produces top-10 dCor features or exits with clear reason if no dataset is found.

Phase 4 — Tests & scripts
Append (or keep) in package.json:

json
Copy
Edit
{
  "scripts": {
    "preflight:math": "tsx tools/math_preflight.ts",
    "ablation:features": "tsx tools/feature_ablation.ts",
    "canary:launch": "tsx tools/canary_launch.ts",
    "drill:rollback": "tsx tools/rollback_drill.ts",
    "brain:test:math": "vitest run server/brain/models/*.spec.ts server/brain/exec/*.spec.ts server/brain/safe/*.spec.ts"
  }
}
Minimal adapter spec test
Create tools/__tests__/adapters.spec.ts:

ts
Copy
Edit
import { describe,it,expect } from "vitest";
import { loadFrozenDataset, runBacktestSlice } from "../preflight_adapters";
describe("adapters", ()=>{
  it("loadFrozenDataset returns ok|fail with provenance", async ()=>{
    const r:any = await loadFrozenDataset("BTCUSDT","5m");
    expect(r.ok===true || r.ok===false).toBe(true);
    expect(r.provenance || r.reason).toBeDefined();
  });
  it("runBacktestSlice returns ok|fail with provenance", async ()=>{
    const r:any = await runBacktestSlice({ symbols:["BTCUSDT"], timeframe:"5m", buckets:[0.3] });
    expect(r.ok===true || r.ok===false).toBe(true);
  });
});
Phase 5 — Run & verify (print outputs)
arduino
Copy
Edit
pnpm run brain:test:math
pnpm run preflight:math
pnpm run ablation:features
pnpm run canary:launch
pnpm run drill:rollback
Acceptance (global):

preflight writes:

artifacts/preflight/quantile_calibration.json

artifacts/preflight/slippage_check.json

artifacts/preflight/dr_ope.json

canary:launch writes artifacts/promotion/decision.json.

Scripts call local endpoints if present; otherwise log clean fallbacks.

No network to external data providers used in preflight.

Tests pass; no mocks in live code.